{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2bfe47",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:25.174944Z",
     "iopub.status.busy": "2025-10-25T16:03:25.174629Z",
     "iopub.status.idle": "2025-10-25T16:03:25.309345Z",
     "shell.execute_reply": "2025-10-25T16:03:25.308303Z"
    },
    "papermill": {
     "duration": 0.14049,
     "end_time": "2025-10-25T16:03:25.311218",
     "exception": false,
     "start_time": "2025-10-25T16:03:25.170728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru-cholec80  gru-ecrcd\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c973213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:25.317612Z",
     "iopub.status.busy": "2025-10-25T16:03:25.316975Z",
     "iopub.status.idle": "2025-10-25T16:03:29.844087Z",
     "shell.execute_reply": "2025-10-25T16:03:29.843044Z"
    },
    "papermill": {
     "duration": 4.532045,
     "end_time": "2025-10-25T16:03:29.845786",
     "exception": false,
     "start_time": "2025-10-25T16:03:25.313741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 1️⃣ Imports & Device\n",
    "# ====================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe5ce09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:29.851862Z",
     "iopub.status.busy": "2025-10-25T16:03:29.851429Z",
     "iopub.status.idle": "2025-10-25T16:03:29.857668Z",
     "shell.execute_reply": "2025-10-25T16:03:29.856696Z"
    },
    "papermill": {
     "duration": 0.010798,
     "end_time": "2025-10-25T16:03:29.859051",
     "exception": false,
     "start_time": "2025-10-25T16:03:29.848253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 2️⃣ Define GRU Model Class\n",
    "# ====================================================\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=128, layers=2, out=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden, num_layers=layers, batch_first=True,\n",
    "            dropout=dropout if layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.Dropout(0.3), nn.Linear(hidden, out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.gru(x)\n",
    "        return self.head(h[:, -1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2be2b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:29.864680Z",
     "iopub.status.busy": "2025-10-25T16:03:29.864163Z",
     "iopub.status.idle": "2025-10-25T16:03:29.951971Z",
     "shell.execute_reply": "2025-10-25T16:03:29.950841Z"
    },
    "papermill": {
     "duration": 0.092205,
     "end_time": "2025-10-25T16:03:29.953460",
     "exception": false,
     "start_time": "2025-10-25T16:03:29.861255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded both models with matching architectures on cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=128, layers=2, out=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden, num_layers=layers, batch_first=True,\n",
    "            dropout=dropout if layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.Dropout(0.3), nn.Linear(hidden, out))\n",
    "    def forward(self, x):\n",
    "        h,_ = self.gru(x); return self.head(h[:, -1])\n",
    "\n",
    "# paths\n",
    "ECRCD_PATH  = \"/kaggle/input/gru-ecrcd/pytorch/default/1/gru_ecrcd.pth\"\n",
    "CHOLEC_PATH = \"/kaggle/input/gru-cholec80/pytorch/default/1/gru_model.pth\"\n",
    "\n",
    "# input dims\n",
    "ECRCD_INPUT_DIM  = 52\n",
    "CHOLEC_INPUT_DIM = 9\n",
    "\n",
    "# instantiate with correct hidden sizes\n",
    "model_ecrcd  = GRUModel(ECRCD_INPUT_DIM, hidden=128, layers=2).to(DEVICE)\n",
    "model_cholec = GRUModel(CHOLEC_INPUT_DIM, hidden=96,  layers=2).to(DEVICE)   # <-- fix\n",
    "\n",
    "# load weights\n",
    "model_ecrcd.load_state_dict(torch.load(ECRCD_PATH,  map_location=DEVICE))\n",
    "model_cholec.load_state_dict(torch.load(CHOLEC_PATH, map_location=DEVICE))\n",
    "\n",
    "model_ecrcd.eval(); model_cholec.eval()\n",
    "print(\"✅ Loaded both models with matching architectures on\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf53af02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:29.959756Z",
     "iopub.status.busy": "2025-10-25T16:03:29.959303Z",
     "iopub.status.idle": "2025-10-25T16:03:29.970397Z",
     "shell.execute_reply": "2025-10-25T16:03:29.969057Z"
    },
    "papermill": {
     "duration": 0.016313,
     "end_time": "2025-10-25T16:03:29.972271",
     "exception": false,
     "start_time": "2025-10-25T16:03:29.955958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hybrid model ready for inference\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 4️⃣ Hybrid Fusion Model (Late Fusion)\n",
    "# ====================================================\n",
    "class HybridFusionModel(nn.Module):\n",
    "    def __init__(self, model_ecrcd, model_cholec, fusion=\"weighted\", w_e=0.5):\n",
    "        super().__init__()\n",
    "        self.model_ecrcd = model_ecrcd\n",
    "        self.model_cholec = model_cholec\n",
    "        self.fusion = fusion\n",
    "        self.w_e = w_e\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x_ecrcd, x_cholec):\n",
    "        with torch.no_grad():\n",
    "            out_e = self.sigmoid(self.model_ecrcd(x_ecrcd))\n",
    "            out_c = self.sigmoid(self.model_cholec(x_cholec))\n",
    "        if self.fusion == \"weighted\":\n",
    "            out = self.w_e * out_e + (1 - self.w_e) * out_c\n",
    "        else:\n",
    "            out = torch.cat([out_e, out_c], dim=1)\n",
    "        return out\n",
    "\n",
    "# ✅ Instantiate hybrid model\n",
    "hybrid_model = HybridFusionModel(model_ecrcd, model_cholec, fusion=\"weighted\", w_e=0.6)\n",
    "print(\"✅ Hybrid model ready for inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec259c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T16:03:29.980794Z",
     "iopub.status.busy": "2025-10-25T16:03:29.980156Z",
     "iopub.status.idle": "2025-10-25T16:03:30.168293Z",
     "shell.execute_reply": "2025-10-25T16:03:30.167301Z"
    },
    "papermill": {
     "duration": 0.193156,
     "end_time": "2025-10-25T16:03:30.169695",
     "exception": false,
     "start_time": "2025-10-25T16:03:29.976539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Hybrid output shape: torch.Size([2, 3])\n",
      "🔹 Sample predictions: tensor([[0.1340, 0.3514, 0.6824],\n",
      "        [0.9029, 0.8104, 0.8577]])\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 5️⃣ Example Hybrid Inference\n",
    "# ====================================================\n",
    "# Simulated input tensors (batch=2, sequence=300)\n",
    "x_ecrcd = torch.randn(2, 300, ECRCD_INPUT_DIM).to(DEVICE)\n",
    "x_cholec = torch.randn(2, 300, CHOLEC_INPUT_DIM).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = hybrid_model(x_ecrcd, x_cholec)\n",
    "\n",
    "print(\"🔹 Hybrid output shape:\", preds.shape)\n",
    "print(\"🔹 Sample predictions:\", preds)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 479937,
     "modelInstanceId": 464146,
     "sourceId": 617355,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 481196,
     "modelInstanceId": 465359,
     "sourceId": 618811,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.936118,
   "end_time": "2025-10-25T16:03:31.493068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-25T16:03:20.556950",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
