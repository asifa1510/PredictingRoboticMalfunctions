{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13190704,"sourceType":"datasetVersion","datasetId":8359227}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet opencv-python-headless pyarrow\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:31:02.658710Z","iopub.execute_input":"2025-09-29T21:31:02.658940Z","iopub.status.idle":"2025-09-29T21:31:06.753784Z","shell.execute_reply.started":"2025-09-29T21:31:02.658922Z","shell.execute_reply":"2025-09-29T21:31:06.752716Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:31:06.755415Z","iopub.execute_input":"2025-09-29T21:31:06.755666Z","iopub.status.idle":"2025-09-29T21:31:09.844654Z","shell.execute_reply.started":"2025-09-29T21:31:06.755634Z","shell.execute_reply":"2025-09-29T21:31:09.843847Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.4)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.5.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, glob, random, json\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nimport torchvision.transforms as T\nimport cv2\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n\n# Paths (adjust as needed)\nDATA_DIR = Path(\"/kaggle/input/dataset/cholec80\")     # videos + annotations\nWORK_DIR = Path(\"/kaggle/working\")\nWORK_DIR.mkdir(parents=True, exist_ok=True)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:31:12.127011Z","iopub.execute_input":"2025-09-29T21:31:12.127734Z","iopub.status.idle":"2025-09-29T21:31:19.980074Z","shell.execute_reply.started":"2025-09-29T21:31:12.127694Z","shell.execute_reply":"2025-09-29T21:31:19.979376Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\n\nBASE_DIR   = Path(\"/kaggle/input/dataset/cholec80\")\nPHASE_DIR  = BASE_DIR / \"phase_annotations\"\nTOOL_DIR   = BASE_DIR / \"tool_annotations\"\n\ndef load_phase_file(path: Path) -> pd.DataFrame:\n    df = pd.read_csv(path, sep=r\"\\s+|,|\\t\", engine=\"python\")\n    df.columns = [\"Frame\", \"Phase\"]\n    return df\n\ndef load_tool_file(path: Path) -> pd.DataFrame:\n    return pd.read_csv(path, sep=r\"\\s+|,|\\t\", engine=\"python\")\n\ndef load_video_annotations(vid: str) -> pd.DataFrame:\n    phase_path = PHASE_DIR / f\"{vid}-phase.txt\"\n    tool_path  = TOOL_DIR / f\"{vid}-tool.txt\"\n    if not phase_path.exists() or not tool_path.exists():\n        print(f\"⚠️ Missing {vid}\")\n        return None\n    df_phase = load_phase_file(phase_path)\n    df_tool  = load_tool_file(tool_path)\n    df = pd.merge(df_phase, df_tool, on=\"Frame\", how=\"outer\").sort_values(\"Frame\")\n    df = df.ffill()\n    df[\"Video\"] = vid\n    return df\n\nvideos = [f\"video{str(i).zfill(2)}\" for i in range(1,16)]\nann_dfs = [load_video_annotations(v) for v in videos if load_video_annotations(v) is not None]\ndf_all = pd.concat(ann_dfs, ignore_index=True)\n\n# Features\ntool_cols = [\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\"Clipper\",\"Irrigator\",\"SpecimenBag\"]\ndf_all[\"ActiveToolCount\"] = df_all[tool_cols].sum(axis=1)\nphase_map = {p:i for i,p in enumerate(df_all[\"Phase\"].unique())}\ndf_all[\"PhaseID\"] = df_all[\"Phase\"].map(phase_map)\n\nprint(\"✅ Data shape:\", df_all.shape)\nprint(\"Phases:\", phase_map)\ndf_all.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:31:23.261281Z","iopub.execute_input":"2025-09-29T21:31:23.261727Z","iopub.status.idle":"2025-09-29T21:31:31.842464Z","shell.execute_reply.started":"2025-09-29T21:31:23.261693Z","shell.execute_reply":"2025-09-29T21:31:31.841910Z"}},"outputs":[{"name":"stdout","text":"✅ Data shape: (900091, 12)\nPhases: {'Preparation': 0, 'CalotTriangleDissection': 1, 'ClippingCutting': 2, 'GallbladderDissection': 3, 'GallbladderPackaging': 4, 'CleaningCoagulation': 5, 'GallbladderRetraction': 6}\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Frame        Phase  Grasper  Bipolar  Hook  Scissors  Clipper  Irrigator  \\\n0      0  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n1      1  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n2      2  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n3      3  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n4      4  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n\n   SpecimenBag    Video  ActiveToolCount  PhaseID  \n0          0.0  video01              1.0        0  \n1          0.0  video01              1.0        0  \n2          0.0  video01              1.0        0  \n3          0.0  video01              1.0        0  \n4          0.0  video01              1.0        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Phase</th>\n      <th>Grasper</th>\n      <th>Bipolar</th>\n      <th>Hook</th>\n      <th>Scissors</th>\n      <th>Clipper</th>\n      <th>Irrigator</th>\n      <th>SpecimenBag</th>\n      <th>Video</th>\n      <th>ActiveToolCount</th>\n      <th>PhaseID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\n\nallowed_tools = {\n    \"Preparation\": [\"Grasper\", \"Hook\"],\n    \"CalotTriangleDissection\": [\"Grasper\", \"Hook\", \"Scissors\"],\n    \"ClippingCutting\": [\"Grasper\", \"Clipper\"],\n    \"GallbladderDissection\": [\"Grasper\", \"Hook\", \"Scissors\"],\n    \"GallbladderPackaging\": [\"Grasper\", \"SpecimenBag\"],\n    \"CleaningCoagulation\": [\"Grasper\", \"Irrigator\", \"Bipolar\"],\n    \"GallbladderRetraction\": [\"Grasper\"]\n}\n\n# Required tools for critical phases\nrequired_tools = {\n    \"ClippingCutting\": [\"Clipper\"],\n    \"GallbladderPackaging\": [\"SpecimenBag\"]\n}\n\n# Max duration (frames @ 25 fps)\nmax_expected_duration = {\n    \"Preparation\": 5*60*25,\n    \"CalotTriangleDissection\": 20*60*25,\n    \"ClippingCutting\": 5*60*25,\n    \"GallbladderDissection\": 20*60*25,\n    \"GallbladderPackaging\": 5*60*25,\n    \"CleaningCoagulation\": 10*60*25,\n    \"GallbladderRetraction\": 5*60*25,\n}\n\n# Forbidden combos\nforbidden_combos = [(\"Clipper\", \"Scissors\")]\n\ndef apply_rules(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df[\"error_now\"] = 0\n    \n    # Track phase duration\n    df[\"PhaseChange\"] = (df[\"Phase\"] != df[\"Phase\"].shift()).astype(int)\n    df[\"PhaseRun\"] = df.groupby(df[\"Video\"]).PhaseChange.cumsum()\n    df[\"TimeInPhase\"] = df.groupby([\"Video\",\"PhaseRun\"]).cumcount()\n    \n    # Track tool switches\n    df[\"ToolVec\"] = df[[\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\"Clipper\",\"Irrigator\",\"SpecimenBag\"]].values.tolist()\n    df[\"ToolSwitch\"] = df[\"ToolVec\"].ne(df[\"ToolVec\"].shift()).astype(int)\n    df[\"ToolSwitches_5s\"] = df[\"ToolSwitch\"].rolling(window=125, min_periods=1).sum()\n    \n    # Apply rules (row-wise)\n    for idx, row in df.iterrows():\n        phase = row[\"Phase\"]\n        \n        # Rule 1: Tool–phase mismatch\n        for tool in tool_cols:\n            if row[tool] == 1 and tool not in allowed_tools.get(phase, []):\n                df.at[idx, \"error_now\"] = 1\n        \n        # Rule 2: Too many tools\n        if row[\"ActiveToolCount\"] > 2:\n            df.at[idx, \"error_now\"] = 1\n\n        # Rule 3: Required tool missing\n        if phase in required_tools:\n            for req in required_tools[phase]:\n                if row[req] == 0:\n                    df.at[idx, \"error_now\"] = 1\n\n        # Rule 4: Prolonged inactivity\n        if row[\"ActiveToolCount\"] == 0:\n            prev_active = df.loc[:idx, \"ActiveToolCount\"].iloc[::-1].ne(0).idxmax()\n            if idx - prev_active > 30*25:\n                df.at[idx, \"error_now\"] = 1\n\n        # Rule 5: Abrupt tool switches\n        if row[\"ToolSwitches_5s\"] > 3:\n            df.at[idx, \"error_now\"] = 1\n\n        # Rule 6: Phase overrun\n        if row[\"TimeInPhase\"] > max_expected_duration.get(phase, 999999):\n            df.at[idx, \"error_now\"] = 1\n\n        # Rule 7: Forbidden combos\n        for t1, t2 in forbidden_combos:\n            if row[t1] == 1 and row[t2] == 1:\n                df.at[idx, \"error_now\"] = 1\n\n        # Rule 8: Tool appears too early\n        if row[\"SpecimenBag\"] == 1 and phase not in [\"GallbladderPackaging\",\"GallbladderRetraction\"]:\n            df.at[idx, \"error_now\"] = 1\n    \n    return df\n\ndf_rules = apply_rules(df_all)\nprint(\"✅ Errors flagged:\", df_rules[\"error_now\"].sum())\ndf_rules.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:31:34.048977Z","iopub.execute_input":"2025-09-29T21:31:34.049558Z","iopub.status.idle":"2025-09-29T21:33:50.308477Z","shell.execute_reply.started":"2025-09-29T21:31:34.049535Z","shell.execute_reply":"2025-09-29T21:33:50.307852Z"}},"outputs":[{"name":"stdout","text":"✅ Errors flagged: 305377\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Frame        Phase  Grasper  Bipolar  Hook  Scissors  Clipper  Irrigator  \\\n0      0  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n1      1  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n2      2  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n3      3  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n4      4  Preparation      1.0      0.0   0.0       0.0      0.0        0.0   \n\n   SpecimenBag    Video  ActiveToolCount  PhaseID  error_now  PhaseChange  \\\n0          0.0  video01              1.0        0          0            1   \n1          0.0  video01              1.0        0          0            0   \n2          0.0  video01              1.0        0          0            0   \n3          0.0  video01              1.0        0          0            0   \n4          0.0  video01              1.0        0          0            0   \n\n   PhaseRun  TimeInPhase                              ToolVec  ToolSwitch  \\\n0         1            0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]           1   \n1         1            1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]           0   \n2         1            2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]           0   \n3         1            3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]           0   \n4         1            4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]           0   \n\n   ToolSwitches_5s  \n0              1.0  \n1              1.0  \n2              1.0  \n3              1.0  \n4              1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Phase</th>\n      <th>Grasper</th>\n      <th>Bipolar</th>\n      <th>Hook</th>\n      <th>Scissors</th>\n      <th>Clipper</th>\n      <th>Irrigator</th>\n      <th>SpecimenBag</th>\n      <th>Video</th>\n      <th>ActiveToolCount</th>\n      <th>PhaseID</th>\n      <th>error_now</th>\n      <th>PhaseChange</th>\n      <th>PhaseRun</th>\n      <th>TimeInPhase</th>\n      <th>ToolVec</th>\n      <th>ToolSwitch</th>\n      <th>ToolSwitches_5s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Preparation</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>video01</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\nimport pandas as pd\ndef generate_hazard_labels(df: pd.DataFrame, fps: int = 25) -> pd.DataFrame:\n    df = df.copy()\n    df[\"HazardNow\"] = (df[\"error_now\"]\n                       .rolling(window=2*fps, min_periods=1)\n                       .max())\n    df[\"y_10s\"] = df[\"HazardNow\"].shift(-10*fps).fillna(0).astype(int)\n    df[\"y_20s\"] = df[\"HazardNow\"].shift(-20*fps).fillna(0).astype(int)\n    df[\"y_30s\"] = df[\"HazardNow\"].shift(-30*fps).fillna(0).astype(int)\n    return df\n\ndf_labels = generate_hazard_labels(df_rules, fps=25)\nprint(df_labels[[\"Frame\",\"Phase\",\"error_now\",\"HazardNow\",\"y_10s\",\"y_20s\",\"y_30s\"]].head(30))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:34:21.995928Z","iopub.execute_input":"2025-09-29T21:34:21.996487Z","iopub.status.idle":"2025-09-29T21:34:22.350089Z","shell.execute_reply.started":"2025-09-29T21:34:21.996464Z","shell.execute_reply":"2025-09-29T21:34:22.349421Z"}},"outputs":[{"name":"stdout","text":"    Frame        Phase  error_now  HazardNow  y_10s  y_20s  y_30s\n0       0  Preparation          0        0.0      0      0      0\n1       1  Preparation          0        0.0      0      0      0\n2       2  Preparation          0        0.0      0      0      0\n3       3  Preparation          0        0.0      0      0      0\n4       4  Preparation          0        0.0      0      0      0\n5       5  Preparation          0        0.0      0      0      0\n6       6  Preparation          0        0.0      0      0      0\n7       7  Preparation          0        0.0      0      0      0\n8       8  Preparation          0        0.0      0      0      0\n9       9  Preparation          0        0.0      0      0      0\n10     10  Preparation          0        0.0      0      0      0\n11     11  Preparation          0        0.0      0      0      0\n12     12  Preparation          0        0.0      0      0      0\n13     13  Preparation          0        0.0      0      0      0\n14     14  Preparation          0        0.0      0      0      0\n15     15  Preparation          0        0.0      0      0      0\n16     16  Preparation          0        0.0      0      0      0\n17     17  Preparation          0        0.0      0      0      0\n18     18  Preparation          0        0.0      0      0      0\n19     19  Preparation          0        0.0      0      0      0\n20     20  Preparation          0        0.0      0      0      0\n21     21  Preparation          0        0.0      0      0      0\n22     22  Preparation          0        0.0      0      0      0\n23     23  Preparation          0        0.0      0      0      0\n24     24  Preparation          0        0.0      0      0      0\n25     25  Preparation          0        0.0      0      0      0\n26     26  Preparation          0        0.0      0      0      0\n27     27  Preparation          0        0.0      0      0      0\n28     28  Preparation          0        0.0      0      0      0\n29     29  Preparation          0        0.0      0      0      0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"sample = df_labels.sample(50).sort_values(\"Frame\")\nprint(sample[[\"Frame\",\"Phase\",\"error_now\",\"HazardNow\",\"y_10s\",\"y_20s\",\"y_30s\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:34:26.544023Z","iopub.execute_input":"2025-09-29T21:34:26.544267Z","iopub.status.idle":"2025-09-29T21:34:26.576803Z","shell.execute_reply.started":"2025-09-29T21:34:26.544250Z","shell.execute_reply":"2025-09-29T21:34:26.576060Z"}},"outputs":[{"name":"stdout","text":"        Frame                    Phase  error_now  HazardNow  y_10s  y_20s  \\\n298100     46              Preparation          0        0.0      0      0   \n781884    472  CalotTriangleDissection          0        0.0      0      0   \n526203   1796              Preparation          1        1.0      0      0   \n564903   2520  CalotTriangleDissection          0        0.0      0      0   \n414164   3683  CalotTriangleDissection          0        0.0      0      0   \n635221   5287  CalotTriangleDissection          0        0.0      0      0   \n49332    6006              Preparation          0        0.0      0      0   \n812073   6135  CalotTriangleDissection          0        0.0      1      0   \n764877  10716  CalotTriangleDissection          0        0.0      0      0   \n766089  11928  CalotTriangleDissection          0        0.0      0      0   \n540749  16342  CalotTriangleDissection          0        0.0      0      0   \n61979   18653  CalotTriangleDissection          0        0.0      0      0   \n773340  19179    GallbladderDissection          0        0.0      0      0   \n280010  20007  CalotTriangleDissection          0        0.0      0      0   \n802368  20956     GallbladderPackaging          1        1.0      0      0   \n64848   21522  CalotTriangleDissection          0        0.0      0      0   \n69517   26191  CalotTriangleDissection          0        0.0      0      0   \n143604  29302  CalotTriangleDissection          0        0.0      1      0   \n878315  29676    GallbladderDissection          0        0.0      0      0   \n290474  30471    GallbladderDissection          0        0.0      0      0   \n660945  31011     GallbladderPackaging          0        0.0      0      0   \n442576  32095    GallbladderDissection          0        0.0      0      0   \n596221  33838    GallbladderDissection          0        0.0      0      0   \n842586  36648     GallbladderPackaging          1        1.0      1      1   \n80394   37068          ClippingCutting          1        1.0      1      1   \n887337  38698    GallbladderDissection          0        0.0      0      0   \n153326  39024  CalotTriangleDissection          1        1.0      1      1   \n337243  39189     GallbladderPackaging          1        1.0      1      1   \n670714  40780    GallbladderRetraction          1        1.0      1      1   \n398277  41622    GallbladderDissection          0        0.0      0      0   \n847800  41862      CleaningCoagulation          0        0.0      0      0   \n405415  48760      CleaningCoagulation          0        0.0      1      1   \n459491  49010    GallbladderDissection          0        0.0      0      0   \n349878  51824    GallbladderRetraction          0        0.0      1      1   \n614792  52409    GallbladderDissection          0        0.0      0      1   \n409231  52576    GallbladderRetraction          0        1.0      0      0   \n168355  54053  CalotTriangleDissection          1        1.0      1      1   \n355560  57506    GallbladderRetraction          1        1.0      1      1   \n100932  57606    GallbladderDissection          0        0.0      0      0   \n180914  66612  CalotTriangleDissection          1        1.0      1      1   \n112645  69319      CleaningCoagulation          0        1.0      1      1   \n744732  71072    GallbladderDissection          0        0.0      0      0   \n186590  72288  CalotTriangleDissection          1        1.0      1      1   \n752909  79249    GallbladderRetraction          1        1.0      1      1   \n194496  80194  CalotTriangleDissection          1        1.0      1      1   \n493503  83022    GallbladderDissection          1        1.0      1      1   \n199472  85170  CalotTriangleDissection          1        1.0      1      1   \n208113  93811  CalotTriangleDissection          1        1.0      1      1   \n208747  94445  CalotTriangleDissection          1        1.0      1      1   \n507377  96896    GallbladderDissection          1        1.0      1      1   \n\n        y_30s  \n298100      0  \n781884      0  \n526203      0  \n564903      0  \n414164      0  \n635221      0  \n49332       0  \n812073      0  \n764877      0  \n766089      0  \n540749      0  \n61979       0  \n773340      0  \n280010      0  \n802368      0  \n64848       0  \n69517       0  \n143604      0  \n878315      0  \n290474      0  \n660945      0  \n442576      0  \n596221      0  \n842586      1  \n80394       1  \n887337      0  \n153326      1  \n337243      0  \n670714      1  \n398277      0  \n847800      0  \n405415      1  \n459491      0  \n349878      1  \n614792      0  \n409231      0  \n168355      1  \n355560      1  \n100932      0  \n180914      1  \n112645      0  \n744732      0  \n186590      1  \n752909      0  \n194496      1  \n493503      1  \n199472      1  \n208113      1  \n208747      1  \n507377      1  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass SurgeryDataset(Dataset):\n    def __init__(self, df, window_size=3000, fps=25, features=None, targets=None):\n        self.df = df.reset_index(drop=True)\n        self.window_size = window_size\n        self.fps = fps\n        self.features = features or [\"PhaseID\"] + tool_cols + [\"ActiveToolCount\"]\n        self.targets = targets or [\"y_10s\",\"y_20s\",\"y_30s\"]\n\n    def __len__(self):\n        return len(self.df) - self.window_size\n\n    def __getitem__(self, idx):\n        X = self.df.loc[idx:idx+self.window_size-1, self.features].astype(float).values\n        y = self.df.loc[idx+self.window_size-1, self.targets].astype(float).values\n        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n\n# Example usage\nfeatures = [\"PhaseID\"] + tool_cols + [\"ActiveToolCount\"]\ntargets = [\"y_10s\",\"y_20s\",\"y_30s\"]\n\ndataset = SurgeryDataset(df_labels, window_size=3000, features=features, targets=targets)\nX, y = dataset[0]\nprint(\"X:\", X.shape, \"y:\", y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:34:32.143198Z","iopub.execute_input":"2025-09-29T21:34:32.143482Z","iopub.status.idle":"2025-09-29T21:34:32.362828Z","shell.execute_reply.started":"2025-09-29T21:34:32.143460Z","shell.execute_reply":"2025-09-29T21:34:32.362078Z"}},"outputs":[{"name":"stdout","text":"X: torch.Size([3000, 9]) y: tensor([0., 0., 0.])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":" \nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport numpy as np, pandas as pd, random\nfrom sklearn.metrics import (\n    roc_auc_score, average_precision_score, precision_recall_curve, \n    confusion_matrix, classification_report, f1_score, precision_score, recall_score\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\n\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.manual_seed_all(seed)\n        except Exception as e:\n            print(\"CUDA seed issue:\", e)\n\nset_seed(42)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", DEVICE)\n\n\n \nclass SurgeryDataset(Dataset):\n    def __init__(self, df, window_size=300, features=None, targets=None):\n        self.features = features or [\n            \"PhaseID\",\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\n            \"Clipper\",\"Irrigator\",\"SpecimenBag\",\"ActiveToolCount\"\n        ]\n        self.targets = targets or [\"y_10s\",\"y_20s\",\"y_30s\"]\n\n        keep_cols = self.features + self.targets + [\"Frame\"]\n        self.df = df[keep_cols].copy().reset_index(drop=True)\n\n        # sanitize\n        self.df[self.features] = self.df[self.features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n        self.df[self.targets] = self.df[self.targets].apply(pd.to_numeric, errors=\"coerce\").clip(0,1).fillna(0)\n\n        self.window_size = window_size\n\n    def __len__(self):\n        return max(0, len(self.df) - self.window_size)\n\n    def __getitem__(self, idx):\n        X = self.df.loc[idx:idx+self.window_size-1, self.features].astype(np.float32).values\n        y = self.df.loc[idx+self.window_size-1, self.targets].astype(np.float32).values\n        return torch.tensor(X), torch.tensor(y)\n\n\n\nclass GRUModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim=128, num_layers=2, output_dim=3, dropout=0.3):\n        super().__init__()\n        self.gru = nn.GRU(\n            input_dim, hidden_dim, num_layers=num_layers, \n            batch_first=True, dropout=dropout if num_layers>1 else 0.0\n        )\n        self.head = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, x):\n        h, _ = self.gru(x)        # [B,T,H]\n        h_last = h[:, -1, :]      # [B,H]\n        logits = self.head(h_last)  # [B,3]\n        return logits  # raw logits\n\n\ndef compute_pos_weight(loader):\n    total = 0\n    pos = None\n    for _,y in loader:\n        y_np = y.numpy()\n        if pos is None:\n            pos = y_np.sum(axis=0)\n        else:\n            pos += y_np.sum(axis=0)\n        total += y_np.shape[0]\n    neg = total - pos\n    pos = np.clip(pos, 1e-6, None)\n    return torch.tensor((neg/pos).astype(np.float32))\n\ndef build_weighted_sampler(subset, alpha=4.0):\n    # Build sampler using subset indices\n    y_end = []\n    for i in subset.indices:\n        row = subset.dataset.df.loc[i + subset.dataset.window_size - 1, [\"y_10s\",\"y_20s\",\"y_30s\"]]\n        y_end.append(row.sum())\n    w = 1.0 + alpha * (np.array(y_end) > 0).astype(np.float32)\n    return WeightedRandomSampler(weights=torch.tensor(w), num_samples=len(w), replacement=True)\n\ndef best_thresholds(y_true, y_prob):\n    ths = []\n    for i in range(y_true.shape[1]):\n        precision, recall, thresh = precision_recall_curve(y_true[:,i], y_prob[:,i])\n        f1 = (2*precision*recall)/(precision+recall+1e-9)\n        if len(thresh)==0:\n            ths.append(0.5)\n        else:\n            ths.append(float(thresh[np.nanargmax(f1)]))\n    return ths\n\ndef eval_per_horizon(y_true, y_prob, thresholds):\n    out = {}; cms=[]\n    for i, name in enumerate([\"10s\",\"20s\",\"30s\"]):\n        th = thresholds[i]\n        yb = (y_prob[:,i] >= th).astype(int)\n        t = y_true[:,i].astype(int)\n        out[name] = {\n            \"AUROC\": roc_auc_score(t, y_prob[:,i]) if t.mean() not in [0,1] else np.nan,\n            \"AUPRC\": average_precision_score(t, y_prob[:,i]) if t.sum()>0 else np.nan,\n            \"F1\": f1_score(t, yb, zero_division=0),\n            \"Precision\": precision_score(t, yb, zero_division=0),\n            \"Recall\": recall_score(t, yb, zero_division=0),\n            \"Threshold\": th,\n            \"Positives\": int(t.sum())\n        }\n        cms.append(confusion_matrix(t, yb))\n    return out, cms\n\ndef plot_cm(cm, title):\n    plt.figure(figsize=(4,3))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, cmap=\"Blues\")\n    plt.title(title)\n    plt.xlabel(\"Pred\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n\nfeatures = [\n    \"PhaseID\",\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\n    \"Clipper\",\"Irrigator\",\"SpecimenBag\",\"ActiveToolCount\"\n]\ntargets = [\"y_10s\",\"y_20s\",\"y_30s\"]\n\ndf_sub = df_labels.sample(frac=0.15, random_state=42).sort_values(\"Frame\").reset_index(drop=True)\nwindow = 300\nfull_ds = SurgeryDataset(df_sub, window_size=window, features=features, targets=targets)\n\nN = len(full_ds)\nsplit = int(0.8*N)\ntrain_ds, val_ds = torch.utils.data.random_split(\n    full_ds, [split, N-split], generator=torch.Generator().manual_seed(42)\n)\n\n# Sampler + pos_weight computed from subset\nsampler = build_weighted_sampler(train_ds, alpha=6.0)\ntrain_loader_plain = DataLoader(train_ds, batch_size=16, shuffle=False)\npos_weight = compute_pos_weight(train_loader_plain).to(DEVICE)\nprint(\"pos_weight per horizon:\", pos_weight.cpu().numpy())\n\ntrain_loader = DataLoader(train_ds, batch_size=16, sampler=sampler, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n\n\nmodel = GRUModel(\n    input_dim=len(features), hidden_dim=96, num_layers=2, \n    output_dim=len(targets), dropout=0.3\n).to(DEVICE)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n\nhistory = {\"train\":[], \"val\":[]}\n\ndef run_eval(loader):\n    model.eval()\n    ys=[]; ps=[]\n    with torch.no_grad():\n        for X,y in loader:\n            X,y = X.to(DEVICE), y.to(DEVICE)\n            logits = model(X)\n            prob = torch.sigmoid(logits)\n            ys.append(y.cpu().numpy())\n            ps.append(prob.cpu().numpy())\n    if not ys:\n        return None\n    return np.vstack(ys), np.vstack(ps)\n\nbest_val=np.inf; bad=0; patience=3\n\nfor epoch in range(1,6):\n    print(f\"\\n=== Epoch {epoch}/5 ===\")\n    model.train(); tot=0\n    for X,y in tqdm(train_loader, desc=\"Training\", leave=False):\n        X,y = X.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(X)\n        loss = criterion(logits, y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        tot += loss.item()\n\n    train_loss = tot/len(train_loader)\n\n    # val\n    ev = run_eval(val_loader)\n    if ev is None: break\n    y_true,y_prob = ev\n    val_loss = 0\n    with torch.no_grad():\n        for Xv,yv in val_loader:\n            Xv,yv = Xv.to(DEVICE), yv.to(DEVICE)\n            val_loss += criterion(model(Xv), yv).item()\n    val_loss /= len(val_loader)\n\n    scheduler.step(val_loss)\n\n    history[\"train\"].append(train_loss)\n    history[\"val\"].append(val_loss)\n    print(f\"Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n\n    ths = best_thresholds(y_true,y_prob)\n    per_hz,cms = eval_per_horizon(y_true,y_prob,ths)\n    for k,v in per_hz.items():\n        print(f\"[{k}] AUROC={v['AUROC']:.3f} AUPRC={v['AUPRC']:.3f} \"\n              f\"F1={v['F1']:.3f} P={v['Precision']:.3f} R={v['Recall']:.3f} \"\n              f\"thr={v['Threshold']:.2f} Pos={v['Positives']}\")\n    for i,name in enumerate([\"10s\",\"20s\",\"30s\"]):\n        plot_cm(cms[i], f\"Confusion Matrix ({name})\")\n\n    if val_loss < best_val-1e-4:\n        best_val=val_loss; bad=0\n        best_state={k:v.cpu() for k,v in model.state_dict().items()}\n    else:\n        bad+=1\n    if bad>=patience:\n        print(\"Early stopping.\")\n        break\n\nif 'best_state' in locals():\n    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()})\n    print(\"✅ Loaded best model\")\n\n\nplt.plot(history[\"train\"], label=\"Train\")\nplt.plot(history[\"val\"], label=\"Val\")\nplt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\nplt.title(\"Learning Curve\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T21:34:35.883016Z","iopub.execute_input":"2025-09-29T21:34:35.883773Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n\ntorch.save(model.state_dict(), \"gru_model.pth\")\nprint(\"✅ GRU model weights saved as gru_model.pth\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T21:28:38.543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp gru_model.pth /kaggle/working/\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T21:28:38.543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport torch, torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport numpy as np, pandas as pd, random\nfrom sklearn.metrics import (\n    roc_auc_score, average_precision_score, precision_recall_curve,\n    confusion_matrix, f1_score, precision_score, recall_score\n)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\n \ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.manual_seed_all(seed)\n        except Exception as e:\n            print(\"CUDA seed issue:\", e)\n\nset_seed(42)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", DEVICE)\n\n\nclass SurgeryDataset(Dataset):\n    def __init__(self, df, window_size=300, features=None, targets=None):\n        self.features = features or [\n            \"PhaseID\",\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\n            \"Clipper\",\"Irrigator\",\"SpecimenBag\",\"ActiveToolCount\"\n        ]\n        self.targets = targets or [\"y_10s\",\"y_20s\",\"y_30s\"]\n\n        keep_cols = self.features + self.targets + [\"Frame\"]\n        self.df = df[keep_cols].copy().reset_index(drop=True)\n\n        # clean up\n        self.df[self.features] = self.df[self.features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n        self.df[self.targets] = self.df[self.targets].apply(pd.to_numeric, errors=\"coerce\").clip(0,1).fillna(0)\n\n        self.window_size = window_size\n\n    def __len__(self):\n        return max(0, len(self.df) - self.window_size)\n\n    def __getitem__(self, idx):\n        X = self.df.loc[idx:idx+self.window_size-1, self.features].astype(np.float32).values\n        y = self.df.loc[idx+self.window_size-1, self.targets].astype(np.float32).values\n        return torch.tensor(X.flatten()), torch.tensor(y)\n\n \nclass LNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, output_dim=3, dropout=0.3):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim//2, output_dim)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef compute_pos_weight(loader):\n    total=None; pos=None\n    for _,y in loader:\n        y_np = y.numpy()\n        if total is None:\n            total = y_np.shape[0]\n            pos = y_np.sum(axis=0)\n        else:\n            total += y_np.shape[0]\n            pos += y_np.sum(axis=0)\n    neg = total - pos\n    pos = np.clip(pos, 1e-6, None)\n    return torch.tensor((neg/pos).astype(np.float32))\n\ndef build_weighted_sampler(subset, alpha=4.0):\n    \"\"\"Build sampler aligned with train subset\"\"\"\n    df = subset.dataset.df\n    window = subset.dataset.window_size\n    idxs = subset.indices\n    y_end = df.loc[window-1:, [\"y_10s\",\"y_20s\",\"y_30s\"]].sum(axis=1).values\n    y_end = y_end[:len(df)-window+1]   # align to dataset length\n    y_end = y_end[idxs]                # only keep train indices\n    w = 1.0 + alpha * (y_end > 0).astype(np.float32)\n    return WeightedRandomSampler(weights=torch.tensor(w), num_samples=len(w), replacement=True)\n\ndef best_thresholds(y_true, y_prob):\n    ths=[]\n    for i in range(y_true.shape[1]):\n        precision, recall, thresh = precision_recall_curve(y_true[:,i], y_prob[:,i])\n        f1 = (2*precision*recall)/(precision+recall+1e-9)\n        ths.append(float(thresh[np.nanargmax(f1)]) if len(thresh)>0 else 0.5)\n    return ths\n\ndef eval_per_horizon(y_true, y_prob, thresholds):\n    out={}; mats=[]\n    for i,name in enumerate([\"10s\",\"20s\",\"30s\"]):\n        th = thresholds[i]\n        yb = (y_prob[:,i]>=th).astype(int)\n        t = y_true[:,i].astype(int)\n        out[name] = {\n            \"AUROC\": roc_auc_score(t, y_prob[:,i]) if t.mean() not in [0,1] else np.nan,\n            \"AUPRC\": average_precision_score(t, y_prob[:,i]) if t.sum()>0 else np.nan,\n            \"F1\": f1_score(t, yb, zero_division=0),\n            \"Precision\": precision_score(t, yb, zero_division=0),\n            \"Recall\": recall_score(t, yb, zero_division=0),\n            \"Threshold\": th,\n            \"Positives\": int(t.sum())\n        }\n        mats.append(confusion_matrix(t, yb))\n    return out,mats\n\ndef plot_cm(cm,title):\n    plt.figure(figsize=(4.2,3.6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, cmap=\"Blues\")\n    plt.title(title); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n    plt.show()\n\nfeatures = [\n    \"PhaseID\",\"Grasper\",\"Bipolar\",\"Hook\",\"Scissors\",\n    \"Clipper\",\"Irrigator\",\"SpecimenBag\",\"ActiveToolCount\"\n]\ntargets = [\"y_10s\",\"y_20s\",\"y_30s\"]\n\ndf_sub = df_labels.sample(frac=0.15, random_state=42).sort_values(\"Frame\").reset_index(drop=True)\nwindow = 300\nfull_ds = SurgeryDataset(df_sub, window_size=window, features=features, targets=targets)\n\nN=len(full_ds)\nsplit=int(0.8*N)\ntrain_ds,val_ds = torch.utils.data.random_split(\n    full_ds,[split,N-split],generator=torch.Generator().manual_seed(42)\n)\n\nsampler = build_weighted_sampler(train_ds, alpha=6.0)\ntrain_loader_plain = DataLoader(train_ds,batch_size=16,shuffle=False)\npos_weight = compute_pos_weight(train_loader_plain).to(DEVICE)\nprint(\"pos_weight per horizon:\", pos_weight.cpu().numpy())\n\ntrain_loader = DataLoader(train_ds,batch_size=16,sampler=sampler,drop_last=True)\nval_loader = DataLoader(val_ds,batch_size=32,shuffle=False)\n\n\ninput_dim = len(features)*window\nmodel = LNNModel(input_dim=input_dim, hidden_dim=512, output_dim=len(targets)).to(DEVICE)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n\ndef run_eval(loader):\n    model.eval(); ys=[]; ps=[]\n    with torch.no_grad():\n        for X,y in loader:\n            X,y = X.to(DEVICE), y.to(DEVICE)\n            logits = model(X)\n            prob = torch.sigmoid(logits)\n            ys.append(y.cpu().numpy()); ps.append(prob.cpu().numpy())\n    return np.vstack(ys), np.vstack(ps)\n\ntrain_losses=[]; val_losses=[]\nbest_val=np.inf; patience=3; bad=0\n\nfor epoch in range(1,6):\n    model.train(); tot=0\n    for X,y in tqdm(train_loader, desc=f\"LNN Epoch {epoch}/5\"):\n        X,y = X.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(X)\n        loss = criterion(logits,y)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(),1.0)\n        optimizer.step()\n        tot+=loss.item()\n    train_loss=tot/len(train_loader)\n\n    # validation\n    y_true,y_prob=run_eval(val_loader)\n    val_tot=0;c=0\n    with torch.no_grad():\n        for Xv,yv in val_loader:\n            Xv,yv=Xv.to(DEVICE),yv.to(DEVICE)\n            lv=model(Xv)\n            val_tot+=criterion(lv,yv).item();c+=1\n    val_loss=val_tot/c\n    scheduler.step(val_loss)\n\n    train_losses.append(train_loss); val_losses.append(val_loss)\n    print(f\"\\nEpoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n\n    ths=best_thresholds(y_true,y_prob)\n    per_hz,cms=eval_per_horizon(y_true,y_prob,ths)\n    for k,v in per_hz.items():\n        print(f\"[{k}] AUROC={v['AUROC']:.3f} AUPRC={v['AUPRC']:.3f} \"\n              f\"F1={v['F1']:.3f} P={v['Precision']:.3f} R={v['Recall']:.3f} \"\n              f\"thr={v['Threshold']:.2f} Pos={v['Positives']}\")\n    for i,name in enumerate([\"10s\",\"20s\",\"30s\"]):\n        plot_cm(cms[i],f\"LNN Confusion Matrix ({name})\")\n\n    if val_loss<best_val-1e-4:\n        best_val=val_loss; bad=0\n        best_state={k:v.cpu() for k,v in model.state_dict().items()}\n    else:\n        bad+=1\n    if bad>=patience:\n        print(\"Early stopping.\")\n        break\n\nif 'best_state' in locals():\n    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()})\n    print(\"✅ Loaded best LNN model\")\n\n\nplt.figure(figsize=(6,4))\nplt.plot(train_losses,label=\"Train\")\nplt.plot(val_losses,label=\"Val\")\nplt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\nplt.title(\"LNN Learning Curve\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T21:28:38.543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}